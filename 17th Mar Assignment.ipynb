{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12732a79-611f-422f-9441-d0d78f8558c7",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed1b51-c3c4-4191-969a-b0e9134efc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc1592-ec3c-4e45-abab-29ab2004b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Missing values in a dataset refer to the absence of data for certain observations or variables. It occurs when there is no recorded or available information for a specific data point. Missing values can be represented in various ways, such as \"NaN\" (Not a Number), \"NA\" (Not Available), or blank cells.\n",
    "\n",
    "Handling missing values is crucial for several reasons:\n",
    "\n",
    "Accurate Analysis: Missing values can lead to biased or incorrect analyses if not appropriately addressed. Ignoring missing values can result in distorted statistical measures and inaccurate conclusions.\n",
    "Data Completeness: Missing values can impact the completeness and representativeness of the dataset. To ensure a comprehensive analysis, it is important to handle missing values appropriately.\n",
    "Model Performance: Many machine learning algorithms cannot handle missing values directly. Therefore, missing value treatment is necessary to ensure the accurate functioning and performance of the models.\n",
    "\n",
    "\n",
    "algorithms that are not affected by missing values:\n",
    "\n",
    "Decision Tree\n",
    "Random Forest\n",
    "Gradient Boosting Machines (GBM)\n",
    "k-Nearest Neighbors (k-NN)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9246d4e9-2e11-4368-862a-1b026bd74835",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c54d6d3-8a65-431c-b51b-746852482ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "List down techniques used to handle missing data. Give an example of each with python code.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82f95d9b-1849-47da-8cc7-ab20994b0b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of Missing Data\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "data = {'A': [1, 2, None, 4, 5],\n",
    "        'B': [None, 2, 3, None, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove rows with any missing values\n",
    "df_dropped = df.dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Mean/Median/Mode Imputation\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "data = {'A': [1, 2, None, 4, 5],\n",
    "        'B': [None, 2, 3, None, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Impute missing values with the mean\n",
    "df_filled = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fbafe8-f1ec-4831-b97a-64418746cf90",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df2d45-e586-43fc-abb4-dd3af9e6b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae2bb6-76b4-4b7b-8564-8cd8ade5a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imbalanced data refers to a situation in a classification problem where the classes are not represented equally in the dataset\n",
    "\n",
    "If imbalanced data is not handled, several issues may arise:\n",
    "1. Biased Model Performance\n",
    "2. Misleading Evaluation Metrics\n",
    "3. Lack of Generalization\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0569d6-8d87-4264-b0b7-260a290cfe21",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b23358-dd4f-4484-9d37-2a5ad39a9f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c5c4d1-3fc4-423f-b9de-0a84f428b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Up-sampling (Over-sampling):\n",
    "\n",
    "Up-sampling involves increasing the number of samples in the minority class to match the number of samples in the majority class.\n",
    "This can be done by replicating existing samples from the minority class or generating synthetic samples using techniques like SMOTE.\n",
    "Up-sampling is required when the minority class is underrepresented, and we want to provide the model with more examples to learn from and give it a better chance to recognize the patterns of the minority class.\n",
    "Example: Consider a credit card fraud detection dataset where the fraud cases are significantly less common compared to non-fraud cases. Up-sampling the fraud cases can help balance the dataset and enable the model to learn better representations of fraudulent patterns.\n",
    "\n",
    "\n",
    "\n",
    "Down-sampling (Under-sampling):\n",
    "\n",
    "Down-sampling involves reducing the number of samples in the majority class to match the number of samples in the minority class.\n",
    "This can be done by randomly removing instances from the majority class until the desired balance is achieved.\n",
    "Down-sampling is required when the majority class overwhelms the minority class, leading to biased model performance and predictions that heavily favor the majority class.\n",
    "Example: Consider a medical diagnosis dataset where the occurrence of a rare disease is significantly lower than the non-disease cases. In this scenario, down-sampling the non-disease cases can help create a more balanced dataset and prevent the model from being biased towards predicting non-disease cases.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a407e0d-d090-4530-8fa0-39c77f57ae2f",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5179dc55-fd2c-4f0b-bd8f-f9b14f16c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is data Augmentation? Explain SMOTE.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b632bc-3dee-4c13-aa99-b41fd2af0d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data augmentation is a technique used to artificially increase the size of a dataset by creating new synthetic samples based on existing data. It is commonly employed in machine learning tasks, particularly when working with limited or imbalanced datasets.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a specific data augmentation method designed to address the class imbalance problem. It focuses on the minority class by generating synthetic samples to balance the class distribution\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9fea35-a95d-4589-a102-d43890a92552",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a675189b-fdc5-48ca-ba20-f9cb84cad883",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a356cd-ae19-4e3e-819e-4e9291f672a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Outliers in a dataset are data points or observations that significantly deviate from the majority of the other data points. They are values that are unusually high or low in comparison to the rest of the data.\n",
    "\n",
    "It is essential to handle outliers for several reasons:\n",
    "1. Distorted Analysis\n",
    "2. Biased Models\n",
    "3. Unrepresentative Patterns\n",
    "4. Robustness and Generalization\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99579cff-c2e0-4f81-aa18-9aac50c7ec08",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796e7db8-170d-444c-a127-d039ae2a7283",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e5f45-e894-4610-959f-4c17e0ce421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Removal of Missing Data (Deletion)\n",
    "2. Mean/Median/Mode Imputation\n",
    "3. Forward or Backward Fill\n",
    "4. Interpolation Methods\n",
    "5. Model-Based Imputation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02222351-ec95-4745-8349-856dbb7b53fd",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc418778-0f7a-4c1b-b8db-1c22800180b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39717fd-fe00-4fef-a005-4777b4acd3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Missing Data Visualization\n",
    "2. Missing Data Summary\n",
    "3. Missing Data Mechanism Test\n",
    "4. Imputation Comparison\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c43de0-ca35-4088-8300-2d6ce9434438",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e7de90-c670-494d-a963-28dc78784b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "609afa28-0c79-4c10-be08-4d076904cec1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Confusion Matrix and Class-Specific Metrics\\n2. Resampling Techniques\\n3. Class Weighting\\n4. Evaluation Metrics\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Confusion Matrix and Class-Specific Metrics\n",
    "2. Resampling Techniques\n",
    "3. Class Weighting\n",
    "4. Evaluation Metrics\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7045ee5-1f96-47ef-9175-594c5a2816a1",
   "metadata": {},
   "source": [
    "# Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a12867-a360-41c2-9916-d3b98303e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b4de2-ce87-42be-bdc2-9d71b72e14a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Random Under-Sampling\n",
    "2. Cluster-Based Under-Sampling\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6843016-b805-4ab1-bcd3-d39814916b38",
   "metadata": {},
   "source": [
    "# Q11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c44b85-ea97-4f60-802e-5b97c3da3e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da496d2d-d595-400c-a4fc-6b22429caaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Random Over-Sampling\n",
    "2. SMOTE\n",
    "3. Cluster-Based Over-Sampling\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
