{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8031d60b-9ad0-4362-a2ef-119a436f83e1",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b978b6cc-1226-454f-9cf7-b89040e00c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is an ensemble technique in machine learning?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72e33b-0f00-4f44-9501-c3bccd5fb4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "An ensemble technique in machine learning refers to the use of multiple models or algorithms to make predictions or decisions. These models are combined together to form an ensemble, and their predictions are aggregated to achieve better overall performance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7877af-f3da-41ea-89a8-a411c742be6e",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260446ce-6bb6-4e65-9458-037f4bfc882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Why are ensemble techniques used in machine learning?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c895daa7-ce8c-4411-9a30-d913debf7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ensemble techniques are used in machine learning for several reasons:\n",
    "\n",
    "They can help improve predictive accuracy by reducing bias and variance.\n",
    "They can handle complex patterns in data by capturing different aspects through diverse models.\n",
    "They can increase robustness by reducing the impact of individual model errors.\n",
    "They can provide more reliable and stable predictions by combining the strengths of multiple models.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d84887e-791c-4b49-9b64-2f212e420791",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08401e18-970f-4b14-8ade-2cdb6bb13595",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is bagging?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff49af-1ec5-4149-b8df-e817dbc0e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bagging, short for bootstrap aggregating, is an ensemble technique where multiple models are trained on different bootstrap samples of the training data. Each model is trained independently, and their predictions are combined, typically by averaging, to obtain the final prediction. Bagging helps reduce variance and improve generalization performance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6eb8cc-005b-480b-bcaa-0e9a656fc0c1",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da923825-b5f1-4792-9a64-814071fc0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is boosting?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7cb546-790b-42da-9283-1e567c673c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Boosting is another ensemble technique where multiple weak models are combined to create a strong model. Boosting works iteratively by training models in sequence, where each subsequent model focuses on the examples that were misclassified by the previous models. Boosting aims to improve both bias and variance, leading to better overall performance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb9b89-4814-4d8e-9369-34f3a7cc5069",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3865540-6cde-44df-9aea-d3c4a838ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are the benefits of using ensemble techniques?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6813b9e3-0d0b-4a44-a57a-d9b648599735",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Benefits of using ensemble techniques include:\n",
    "\n",
    "Improved prediction accuracy and generalization performance.\n",
    "Better handling of complex patterns and capturing diverse aspects of the data.\n",
    "Increased robustness and reduced impact of individual model errors.\n",
    "Ability to handle large and high-dimensional datasets effectively.\n",
    "Flexibility in combining different models and learning algorithms.\n",
    "Enhanced interpretability through model averaging and consensus predictions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e88f7b-81bb-4db3-a85d-806b9e4a2e07",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc1d64-52a3-44b6-b2d6-0afa2384b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Are ensemble techniques always better than individual models?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaac29b-2c3d-43d0-82c0-1401bd474062",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ensemble techniques are generally effective and often outperform individual models. However, it's not always guaranteed that ensemble techniques will perform better in every scenario. The success of ensemble techniques depends on various factors such as the quality and diversity of the base models, the nature and complexity of the data, and the specific problem at hand. In some cases, a single well-tuned model might be sufficient and perform equally well or even better than an ensemble.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381c560a-b448-40ac-bdb6-581b10018dc1",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eeb270-0cc0-405b-a1c9-ef862fcf3e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How is the confidence interval calculated using bootstrap?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908fc2c-b98c-46b0-b938-2f74f03b7102",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The confidence interval using bootstrap can be calculated by taking the percentiles of the bootstrap distribution. Typically, the 95% confidence interval is estimated by taking the 2.5th and 97.5th percentiles of the bootstrap distribution.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa9f6d7-39f1-4cb5-9d59-426e35dd682d",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80621dc8-52f5-46cc-94da-81fc04553f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How does bootstrap work and What are the steps involved in bootstrap?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f1f7b-480c-419e-8962-ac88ebd78e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bootstrap is a resampling technique used to estimate the sampling distribution of a statistic. It involves the following steps:\n",
    "\n",
    "Sampling with replacement: Create multiple bootstrap samples by randomly selecting observations from the original sample with replacement.\n",
    "Calculate the statistic: Compute the desired statistic (e.g., mean, median, standard deviation) on each bootstrap sample.\n",
    "Repeat steps 1 and 2: Repeat the sampling and statistic calculation process multiple times to obtain a distribution of the statistic.\n",
    "Estimate the confidence interval: Calculate the percentiles of the bootstrap distribution to estimate the confidence interval for the statistic.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d258c38-b325-4e24-b122-d9ae5f6ca642",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a356520-c787-4a13-b262-ce9ccd1b27e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A researcher wants to estimate the mean height of a population of trees. They measure the height of a sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use bootstrap to estimate the 95% confidence interval for the population mean height.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72277251-88d5-44cd-abea-9902ca737a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To estimate the 95% confidence interval for the population mean height using bootstrap, the following steps can be followed:\n",
    "\n",
    "Create multiple bootstrap samples: Randomly select 50 heights from the given sample of 50 trees with replacement to create multiple bootstrap samples.\n",
    "Calculate the mean height: Calculate the mean height for each bootstrap sample.\n",
    "Repeat steps 1 and 2: Repeat the process of creating bootstrap samples and calculating the mean height a large number of times (e.g., 1000 times).\n",
    "Estimate the confidence interval: Calculate the 2.5th and 97.5th percentiles of the distribution of mean heights obtained from the bootstrap samples. These percentiles represent the lower and upper bounds of the 95% confidence interval for the population mean height, respectively.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
