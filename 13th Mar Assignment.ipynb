{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af898bcd-a647-48ec-a1ca-deff55f8a7d6",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72abc8e9-740f-47a3-81e9-d8bc48b874c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35584c37-839e-4091-a119-a781f42dfbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ANOVA (Analysis of Variance) has several assumptions that need to be met in order to ensure the validity of the results. These assumptions are:\n",
    "\n",
    "1. Independence: The observations within each group are independent of each other. Violation of this assumption occurs when there is dependence or correlation between the observations. For example, if the data points within each group are paired or clustered in some way, such as repeated measurements on the same subjects, the independence assumption may be violated.\n",
    "2. Normality: The residuals (the differences between observed values and predicted values) within each group are normally distributed. Violation of this assumption occurs when the residuals are not normally distributed. For example, if the residuals follow a skewed or non-normal distribution, it can affect the accuracy of the ANOVA results.\n",
    "3. Homogeneity of Variance: The variance of the residuals is constant across all groups. Violation of this assumption occurs when there are unequal variances across the groups. For example, if one group has much larger variances than the others, it can lead to biased results in the ANOVA analysis.\n",
    "\n",
    "Violations of these assumptions can impact the validity of the ANOVA results. Here are some examples of how the violations can affect the analysis:\n",
    "\n",
    "- Independence violation: In a study where the observations within each group are not independent, such as a repeated measures design where the same subjects are measured multiple times, the assumption of independence is violated. This can lead to inflated Type I error rates and invalid conclusions.\n",
    "- Normality violation: If the residuals within each group do not follow a normal distribution, the assumptions related to p-values, confidence intervals, and hypothesis testing may not hold. Non-normality can affect the accuracy of the p-values and lead to incorrect conclusions about the significance of the group differences.\n",
    "- Homogeneity of Variance violation: When the variances are not equal across the groups, the assumption of homogeneity of variance is violated. This can result in inaccurate F-statistics, p-values, and confidence intervals. If the group with larger variances has a larger impact on the overall analysis, it can lead to biased conclusions.\n",
    "\n",
    "It is important to assess these assumptions before conducting an ANOVA analysis. If any of the assumptions are violated, alternative analysis methods or adjustments may be necessary, such as non-parametric tests or transformations of the data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998a6911-bd75-4787-9c6d-dadc1fb0d8c4",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f814df35-9637-4c19-a120-61780ed10b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are the three types of ANOVA, and in what situations would each be used?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c10ca31-e0e7-4ecc-8f35-980ccb62d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "One-Way ANOVA: This type of ANOVA is used when there is only one categorical independent variable (factor) with two or more groups, and the goal is to compare the means of these groups. It tests whether there are significant differences between the means of the groups. One-Way ANOVA is appropriate when there is a single factor influencing the response variable. For example, you might use One-Way ANOVA to compare the effectiveness of different treatments on patient outcomes.\n",
    "Two-Way ANOVA: Two-Way ANOVA is used when there are two categorical independent variables (factors) and their interaction, and the goal is to examine the main effects of each factor and their interaction on the response variable. It allows for investigating the effects of two independent variables simultaneously. Two-Way ANOVA is appropriate when there are two factors influencing the response variable, and you want to determine the effects of each factor separately as well as their combined effect. For example, you might use Two-Way ANOVA to study the effects of both gender and age group on test scores.\n",
    "Three-Way ANOVA: Three-Way ANOVA extends the concept of Two-Way ANOVA by including three categorical independent variables (factors) and their interactions. It allows for investigating the main effects of each factor, the interactions between pairs of factors, and the three-way interaction on the response variable. Three-Way ANOVA is used when there are three factors influencing the response variable, and you want to explore their individual effects and the combined effects of their interactions. This type of ANOVA is less common and typically applied in complex experimental designs with multiple factors.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8099e54-76db-42f7-a14d-b73cb1849297",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6d77f-8039-44c9-9337-0e910d25ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a687c-ac11-498d-b953-cd197ece6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The partitioning of variance in ANOVA refers to dividing the total variation in the response variable into different sources. It helps understand the relative contributions of factors or sources of variation. It is important because it allows us to assess the impact of independent variables, determine statistical significance, and draw meaningful conclusions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cb9591-9b09-48ed-939c-db9072d73bfd",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf473d-0816-449c-95cb-9eb3b39082f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ac0ec1-d621-42a2-b42a-b80d7ce1e96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 230.0\n",
      "SSE: 90.0\n",
      "SSR: 140.0\n",
      "F-statistic: 3.857142857142857\n",
      "p-value: 0.05086290933139865\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Example data for three groups\n",
    "group1 = np.array([1, 2, 3, 4, 5])\n",
    "group2 = np.array([2, 4, 6, 8, 10])\n",
    "group3 = np.array([3, 6, 9, 12, 15])\n",
    "\n",
    "# Concatenate the data from all groups\n",
    "data = np.concatenate((group1, group2, group3))\n",
    "\n",
    "# Calculate the one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "mean_data = np.mean(data)\n",
    "sst = np.sum((data - mean_data) ** 2)\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "sse = np.sum((np.mean(group1) - mean_data) ** 2) * len(group1) + \\\n",
    "      np.sum((np.mean(group2) - mean_data) ** 2) * len(group2) + \\\n",
    "      np.sum((np.mean(group3) - mean_data) ** 2) * len(group3)\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "print(\"SST:\", sst)\n",
    "print(\"SSE:\", sse)\n",
    "print(\"SSR:\", ssr)\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6512d6e7-27b4-442b-b2e2-0e4b8f3008cb",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c15c12b-731c-4687-a7d1-d8adca626b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32da3e18-4555-47de-8cd9-4ebdc3717f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of A: 90.00000000000007\n",
      "Main Effect of B: 9.663546088957395e-30\n",
      "Interaction Effect: 3.1554436208840472e-30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "data = pd.DataFrame({'A': [1, 2, 3, 4, 5],\n",
    "                     'B': [2, 4, 6, 8, 10],\n",
    "                     'Y': [3, 6, 9, 12, 15]})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Y ~ A + B + A:B', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract main effects and interaction effects\n",
    "main_effect_A = anova_table.loc['A', 'sum_sq'] / anova_table.loc['A', 'df']\n",
    "main_effect_B = anova_table.loc['B', 'sum_sq'] / anova_table.loc['B', 'df']\n",
    "interaction_effect = anova_table.loc['A:B', 'sum_sq'] / anova_table.loc['A:B', 'df']\n",
    "\n",
    "print(\"Main Effect of A:\", main_effect_A)\n",
    "print(\"Main Effect of B:\", main_effect_B)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d4c30-7e25-460a-ba9e-dea4ea8e9f31",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5127f68-a471-4382-9b51-0e0774996940",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a766317-9b3e-4ded-9579-b40b1378fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The F-statistic represents the ratio of the between-group variability to the within-group variability. A larger F-statistic indicates a greater difference between the group means relative to the variability within the groups. In this case, the obtained F-statistic of 5.23 suggests that the between-group differences are significant compared to the within-group variability.\n",
    "The p-value of 0.02 indicates the probability of observing such a large F-statistic by chance, assuming the null hypothesis (no difference between the groups) is true. Since the p-value is less than the significance level (typically 0.05), we reject the null hypothesis and conclude that there are statistically significant differences between the groups.\n",
    "In terms of interpretation, we can say that there is strong evidence to suggest that at least one of the group means is significantly different from the others. However, the ANOVA test does not specifically identify which group(s) differ. To determine the specific group differences, further post-hoc tests or pairwise comparisons can be conducted.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af936ed-9656-45e8-9046-4705540a5ab1",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2546f1-8403-492e-98fe-e3afe678a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe8f9e4-c3f8-4b73-932b-45a5da356fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here are a few approaches commonly used to handle missing data in this context:\n",
    "\n",
    "Complete Case Analysis (Listwise Deletion): This approach involves excluding any participants with missing data from the analysis. While it is straightforward to implement, it may lead to biased results if the missingness is related to the variables under study, potentially compromising the representativeness and generalizability of the findings.\n",
    "Pairwise Deletion: This approach includes all available data for each individual analysis, allowing for different sample sizes across variables. However, it may introduce bias if the missingness is related to specific variables or if there is dependence between missing and observed data.\n",
    "Imputation: Imputation involves estimating the missing values based on available information. Various imputation methods can be used, such as mean imputation, regression imputation, or multiple imputation. Imputation can help retain the sample size and preserve statistical power but assumes that the data are missing at random and that the imputation model adequately captures the missingness mechanism.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceebe6ae-94c1-4318-895b-4d018730c915",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd0a8c0-22ee-40b5-ba6e-98ffb8982397",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada94d0-bb0f-4d44-b901-c95e6a921466",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "After conducting an ANOVA and finding a significant overall effect, post-hoc tests are performed to determine which specific group means differ from each other. Some common post-hoc tests used after ANOVA include:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD): Tukey's HSD test compares all possible pairs of group means and provides simultaneous confidence intervals. It is commonly used when there are equal sample sizes and variances across groups. This test controls the family-wise error rate, making it suitable for multiple comparisons.\n",
    "2. Bonferroni Correction: The Bonferroni correction adjusts the significance level for multiple comparisons. It divides the desired alpha level by the number of pairwise comparisons. This method is conservative but ensures an overall type I error rate.\n",
    "3. Scheffe's Test: Scheffe's test is a conservative post-hoc test that maintains a family-wise error rate for any set of linear combinations of group means. It is useful when there are unequal sample sizes and variances across groups or when exploring complex hypotheses.\n",
    "4. Sidak's Test: Sidak's test is another method for controlling the family-wise error rate in multiple comparisons. It is less conservative than Bonferroni correction but more conservative than Tukey's HSD test.\n",
    "5. Fisher's Least Significant Difference (LSD): Fisher's LSD test compares pairs of means by conducting t-tests. It is less conservative than Bonferroni correction but does not control the family-wise error rate. It is useful when there are equal sample sizes and variances across groups.\n",
    "\n",
    "The choice of post-hoc test depends on various factors, including the research design, sample sizes, and assumptions. Generally, Tukey's HSD is preferred due to its balance between controlling the overall type I error rate and power. Scheffe's test and Bonferroni correction are more conservative but useful when exploring specific hypotheses. Fisher's LSD is less conservative but should be used with caution.\n",
    "Example scenario: Suppose a researcher conducts an experiment comparing the effectiveness of four different treatments for pain relief. After performing an ANOVA, they find a significant overall effect. To determine which specific treatment groups differ from each other, they would conduct post-hoc tests, such as Tukey's HSD or Bonferroni correction, to compare the mean pain relief scores between pairs of treatments. This helps identify which treatments are significantly different and provides a more nuanced understanding of the findings.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b11a915-4f52-440c-90b9-d947868a1a70",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f38ccc-7a8a-4717-bdca-98b2612efd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fc913f0-18d5-41de-8644-02a2de2bfe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Way ANOVA Results\n",
      "---------------------\n",
      "F-statistic: 1055.021967553837\n",
      "p-value: 6.49580749021216e-88\n",
      "There are significant differences between the mean weight loss of the diets.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Weight loss data for each diet\n",
    "diet_A = np.array([2.5, 3.1, 1.8, 2.9, 2.2, 2.4, 3.0, 2.6, 2.1, 2.8,\n",
    "                   2.7, 2.3, 2.9, 2.6, 2.5, 2.2, 2.7, 2.8, 2.9, 2.4,\n",
    "                   2.6, 2.5, 2.3, 2.7, 2.8, 2.4, 2.2, 2.6, 2.5, 2.9,\n",
    "                   2.7, 2.3, 2.8, 2.5, 2.6, 2.7, 2.4, 2.2, 2.9, 2.8,\n",
    "                   2.5, 2.7, 2.6, 2.8, 2.9, 2.5, 2.2, 2.4, 2.6, 2.3])\n",
    "\n",
    "diet_B = np.array([1.7, 1.8, 2.0, 1.9, 1.6, 1.8, 1.7, 2.1, 2.0, 1.8,\n",
    "                   1.6, 1.9, 1.8, 1.7, 2.2, 1.9, 2.0, 1.6, 1.8, 1.7,\n",
    "                   2.1, 1.8, 1.7, 1.6, 1.9, 1.8, 1.7, 2.0, 1.6, 1.8,\n",
    "                   1.7, 2.2, 1.9, 2.0, 1.6, 1.8, 1.7, 2.1, 1.8, 1.7,\n",
    "                   1.6, 1.9, 1.8, 1.7, 2.0, 1.6, 1.8, 1.7, 2.2, 1.9])\n",
    "\n",
    "diet_C = np.array([3.8, 3.7, 3.9, 4.1, 3.5, 3.6, 4.0, 3.8, 3.9, 3.7,\n",
    "                   4.1, 3.5, 3.6, 4.0, 3.8, 3.9, 3.7, 4.1, 3.5, 3.6,\n",
    "                   4.0, 3.8, 3.9, 3.7, 4.1, 3.5, 3.6, 4.0, 3.8, 3.9,\n",
    "                   3.7, 4.1, 3.5, 3.6, 4.0, 3.8, 3.9, 3.7, 4.1, 3.5,\n",
    "                   3.6, 4.0, 3.8, 3.9, 3.7, 4.1, 3.5, 3.6, 4.0, 3.8])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"One-Way ANOVA Results\")\n",
    "print(\"---------------------\")\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"There are significant differences between the mean weight loss of the diets.\")\n",
    "else:\n",
    "    print(\"There are no significant differences between the mean weight loss of the diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4362b7-7cc6-4ded-954e-756381012604",
   "metadata": {},
   "source": [
    "# Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc15d92b-8c46-464c-8406-33ccd7c35a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b334dbe-0216-45d3-be6b-5e30abaf7d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 sum_sq    df             F    PR(>F)\n",
      "C(Software)                4.300000e+01   2.0  2.150000e+01  0.000108\n",
      "C(Experience)              3.813341e-28   1.0  3.813341e-28  1.000000\n",
      "C(Software):C(Experience)  9.000000e+00   2.0  4.500000e+00  0.034815\n",
      "Residual                   1.200000e+01  12.0           NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a dataframe with the data\n",
    "data = pd.DataFrame({\n",
    "    'Software': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'] * 2,\n",
    "    'Experience': ['Novice'] * 9 + ['Experienced'] * 9,\n",
    "    'Time': [10, 12, 11, 13, 15, 14, 8, 9, 10, 9, 10, 11, 14, 12, 13, 11, 12, 10]\n",
    "})\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ccd772-f7b8-4642-8267-278a6e659b48",
   "metadata": {},
   "source": [
    "# Q11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30198973-e5d6-4e28-84e8-39d05b75fcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8356d512-64cc-4d94-a14b-047293406123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: -4.316398519082441\n",
      "P-Value: 2.5039591073846333e-05\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1    group2    meandiff p-adj lower  upper  reject\n",
      "--------------------------------------------------------\n",
      "Control Experimental   6.3061   0.0 3.4251 9.1872   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate random test scores for the control and experimental groups\n",
    "np.random.seed(42)\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=100)\n",
    "experimental_scores = np.random.normal(loc=75, scale=12, size=100)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Print the t-statistic and p-value\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "\n",
    "# Perform post-hoc test (Tukey's HSD)\n",
    "data = pd.DataFrame({\n",
    "    'Scores': np.concatenate([control_scores, experimental_scores]),\n",
    "    'Group': ['Control'] * 100 + ['Experimental'] * 100\n",
    "})\n",
    "posthoc = pairwise_tukeyhsd(data['Scores'], data['Group'])\n",
    "\n",
    "# Print the post-hoc test results\n",
    "print(posthoc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f177dbf1-be9d-42d7-82d6-fadf605216a8",
   "metadata": {},
   "source": [
    "# Q12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bcb102-56c3-4e6c-a4eb-cb221c9d18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d8989fb-7833-483e-bb0a-408078fbac35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 29, but rank is 5\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 58, but rank is 20\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       sum_sq    df             F    PR(>F)\n",
      "C(Store)         3.246523e-10   2.0  1.220381e-14  1.000000\n",
      "C(Day)           7.224219e+05  29.0  1.872837e+00  0.112527\n",
      "C(Store):C(Day)  5.553506e+05  58.0  7.198570e-01  0.790324\n",
      "Residual         7.980760e+05  60.0           NaN       NaN\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "=======================================================\n",
      " group1  group2 meandiff p-adj   lower    upper  reject\n",
      "-------------------------------------------------------\n",
      "Store A Store B   0.0333    1.0 -70.5651 70.6318  False\n",
      "Store A Store C      2.3 0.9967 -68.2984 72.8984  False\n",
      "Store B Store C   2.2667 0.9968 -68.3318 72.8651  False\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Create a dataframe with sales data for each store and day\n",
    "np.random.seed(42)\n",
    "data = pd.DataFrame({\n",
    "    'Day': np.repeat(range(30), 3),\n",
    "    'Store': ['Store A'] * 30 + ['Store B'] * 30 + ['Store C'] * 30,\n",
    "    'Sales': np.random.randint(100, 500, size=90)\n",
    "})\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "model = ols('Sales ~ C(Store) + C(Day) + C(Store):C(Day)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n",
    "\n",
    "# Perform post-hoc test (Tukey's HSD)\n",
    "posthoc = pairwise_tukeyhsd(data['Sales'], data['Store'])\n",
    "\n",
    "# Print the post-hoc test results\n",
    "print(posthoc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
