{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "161a051a-7b76-4173-b3bf-73d2920964fb",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be7e2a-2415-422b-b0e8-400df228f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is Random Forest Regressor?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34035d6-3a7a-4e58-940a-a251b08cc9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Random Forest Regressor is a machine learning algorithm that is based on the ensemble technique of Random Forest. It is used for regression tasks, where the goal is to predict continuous numerical values. Random Forest Regressor combines the predictions of multiple decision trees to make more accurate and robust predictions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2234ed3e-781f-48a8-8d07-e16c7eea530f",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21565f36-c169-43e2-99cf-518a4cec9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How does Random Forest Regressor reduce the risk of overfitting?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe026ea-c02b-4753-b19e-73802ba1a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Random feature selection: At each node of the decision tree, instead of considering all features, a random subset of features is considered for splitting. This introduces randomness and reduces the likelihood of individual trees overfitting to specific features.\n",
    "Bootstrap sampling: Random Forest Regressor uses bootstrap sampling to create different subsets of the training data for each decision tree. This sampling introduces diversity in the training data, reducing the impact of individual outliers or noisy data points.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4f043a-29f1-4992-9792-ce3593c5fa06",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e87da3b-ff85-47af-88eb-3519070c846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a93a95-c970-4463-ab36-ded4ca1da497",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Random Forest Regressor aggregates the predictions of multiple decision trees by taking the average (or weighted average) of the predictions made by each individual tree. For regression tasks, the final prediction is the average of the predictions from all the trees in the ensemble. This aggregation helps to reduce variance and improve the overall prediction accuracy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab2ffd-6d66-459f-bb20-f36f67c13d1a",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ccfe4a-d425-4316-8741-0f0dc1dd7f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are the hyperparameters of Random Forest Regressor?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd60cd9-bcc5-46bf-b13f-deb09845f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some of the important hyperparameters of Random Forest Regressor include:\n",
    "\n",
    "n_estimators: The number of decision trees in the ensemble.\n",
    "max_depth: The maximum depth of each decision tree.\n",
    "min_samples_split: The minimum number of samples required to split an internal node.\n",
    "max_features: The number of features to consider when looking for the best split.\n",
    "bootstrap: Whether to use bootstrap samples or not.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27df588f-d9a4-409f-b6f1-b481257cc69d",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba4959-9e5a-4420-98a9-28b62dc6517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04be71ee-13af-439d-94ed-6c2502268a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The main difference between Random Forest Regressor and Decision Tree Regressor is that Random Forest Regressor uses an ensemble of multiple decision trees, whereas Decision Tree Regressor uses a single decision tree. Random Forest Regressor incorporates randomness and aggregation of multiple trees, which helps reduce overfitting and improve generalization performance. Decision Tree Regressor, on the other hand, can be more prone to overfitting as it may learn and replicate the patterns in the training data more closely.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f6a8f-21db-4934-940d-fa8b4fa68916",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947a825e-bdff-4ad5-9990-e5f9779ead34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are the advantages and disadvantages of Random Forest Regressor?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1c5535-91c9-416e-8637-56dafe660534",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Advantages of Random Forest Regressor:\n",
    "\n",
    "It provides good prediction accuracy and generalization performance.\n",
    "It can handle high-dimensional data and large datasets effectively.\n",
    "It is resistant to overfitting due to the ensemble nature and randomness.\n",
    "It can handle both numerical and categorical features without requiring extensive preprocessing.\n",
    "\n",
    "\n",
    "Disadvantages of Random Forest Regressor:\n",
    "\n",
    "The resulting model can be less interpretable compared to a single decision tree.\n",
    "It can be computationally expensive, especially for large ensembles or high-dimensional data.\n",
    "The hyperparameter tuning process can be time-consuming.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2af616-f3c9-47ad-ab79-0973ecae9999",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd0394c-0594-45f6-a5b7-f52e3e3ad5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is the output of Random Forest Regressor?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec7d83-b09e-45e2-a04e-2cd11ab59a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The output of Random Forest Regressor is a continuous numerical value. It predicts the target variable as a numerical value based on the input features and the learned patterns from the training data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d540ea3-a2c3-4611-a669-35b20f650588",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90f882a-dfc8-42ad-9bc5-ecdc01778730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Can Random Forest Regressor be used for classification tasks?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a839fd9-61cd-4bda-906b-f40aafe7bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "While Random Forest Regressor is primarily used for regression tasks, it can also be adapted for classification tasks by modifying the aggregation method. In classification, instead of averaging the predictions, Random Forest Classifier assigns class labels based on majority voting among the ensemble of decision trees. So, Random Forest Regressor can be used for classification tasks by modifying the output aggregation step. However, it is more commonly used for regression tasks, and Random Forest Classifier is specifically designed for classification tasks.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
