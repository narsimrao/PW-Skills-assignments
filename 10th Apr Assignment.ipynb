{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26781ea2-faa1-4c32-901c-e89e34953d7f",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1353cf47-dd5b-4018-a826-57b216884568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A company conducted a survey of its employees and found that 70% of the employees use the\n",
    "company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
    "probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc3451-2c76-49c0-9d59-ada17faa5617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A: Employee uses the health insurance plan\n",
    "B: Employee is a smoker\n",
    "\n",
    "We are given:\n",
    "\n",
    "P(A) = 0.70 (probability of an employee using the health insurance plan)\n",
    "P(B|A) = 0.40 (probability of an employee being a smoker given that they use the health insurance plan)\n",
    "\n",
    "We want to calculate P(B|A), the probability of an employee being a smoker given that they use the health insurance plan.\n",
    "\n",
    "By Bayes' theorem, we have:\n",
    "\n",
    "P(B|A) = (P(A|B) * P(B)) / P(A)\n",
    "\n",
    "P(A|B) is the probability of an employee using the health insurance plan given that they are a smoker. This information is not provided in the question, so we cannot calculate the exact value of P(B|A) without this information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa666f00-00f2-49a3-aec3-bfea06a08e84",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1adb5a-5cc4-476d-a114-f06e588e4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb4f55-d428-41f3-8c87-e19327cf3f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bernoulli Naive Bayes: It is used when the features (predictors) are binary variables (0 or 1), indicating the absence or presence of a particular feature. It assumes that each feature is conditionally independent given the class label.\n",
    "Multinomial Naive Bayes: It is used when the features are discrete and can take on multiple discrete values. It is commonly used for text classification, where the features represent word counts or frequencies. It also assumes conditional independence of features given the class label.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7717dd7c-425f-4d36-8cc9-fed9b78eab1a",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20bdb3-0a06-48bc-951d-2f2a7d2a3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How does Bernoulli Naive Bayes handle missing values?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57377a3-da68-4462-bdc8-a4060123e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bernoulli Naive Bayes does not handle missing values explicitly. It assumes that the absence or presence of a particular feature (binary variable) is sufficient to make predictions. Therefore, if a feature has missing values, they are typically treated as if the feature is absent (0).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e159c6-b83b-4887-b1f2-84b35e507067",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a34b175-0bfd-40fb-a006-2ea58423c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f146c76d-a5a0-4e7f-a61a-b8fcae28b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gaussian Naive Bayes can be used for multi-class classification. It assumes that the continuous features follow a Gaussian (normal) distribution and calculates the likelihood using the mean and variance of each class. It applies Bayes' theorem to calculate the posterior probabilities and assigns the class with the highest probability as the predicted class. Gaussian Naive Bayes can be extended to handle multiple classes by using a one-vs-all or one-vs-one approach, where multiple binary classifiers are trained to distinguish between each pair of classes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c258688-5d77-4874-af67-85f0ea7440c1",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426a70a7-e3cf-40b9-8dc8-f0d0828fa378",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assignment\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb5082f-0f2c-4aaa-b7d9-5445de2403ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  spam  \n",
       "0                       278     1  \n",
       "1                      1028     1  \n",
       "2                      2259     1  \n",
       "3                       191     1  \n",
       "4                       191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# https://raw.githubusercontent.com/narsimrao/PW-Skills-assignments/main/Bengaluru_House_Data.csv\n",
    "df = pd.read_excel(\"https://raw.githubusercontent.com//narsimrao/PW-Skills-assignments/main/spam.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6401994-cc69-4641-898a-fec70a4430c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df[\"spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef48b735-62fe-42c2-93d8-3e383a0dc884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6868a8da-1de9-4c5b-8886-9beb1a4cd9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "gnb=GaussianNB()\n",
    "gnb_cv = cross_val_score(gnb, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42a26e50-698a-49ef-9c2d-d0c765c4e371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8295031055900622"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b0d9676-1fba-4dcf-ac3c-2c1702be4370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8881987577639752"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "brn=BernoulliNB()\n",
    "brn_cv = cross_val_score(brn, X_train, y_train, cv=10)\n",
    "brn_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12cba227-eb21-4de7-abad-99165ae3e591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8009316770186337"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "mn=MultinomialNB()\n",
    "mn_cv = cross_val_score(mn, X_train, y_train, cv=10)\n",
    "mn_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a2d0c-a706-438a-a3da-59097c6d9b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bernaoulli seems to work better than the other models in Naive bayes this may be because that the features ar mostly are 0 and 1 so the data might be quite fit for the bernaoulli Navie bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2dc249-4fb9-4236-b250-c12c5106a5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1d0d1a-d7b6-437c-a11b-5525a955ba3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb85dad0-d4f7-40b9-8fb4-57aa02ec4dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f5eced-906e-4281-a999-9a3e1416f42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fc3b58-57e5-4a37-abf5-d99a42fee1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
