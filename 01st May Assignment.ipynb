{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0acd5f-a787-4205-b717-29be5a68a978",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20970f9a-cbc2-4b3f-abd9-7955b3bfef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is a contingency matrix, and how is it used to evaluate the performance of a classification model?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15c70d-4d20-4c82-a734-b6acc315ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A contingency matrix, also known as a cross-tabulation table, is a table that shows the counts or frequencies of predicted and actual class labels in a classification task. It is used to evaluate the performance of a classification model by providing a summary of how well the model predicted each class label. The contingency matrix allows for the calculation of various evaluation metrics, such as accuracy, precision, recall, and F1-score.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984e0beb-14bf-4e4a-864a-ddf31e247d38",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27567a1a-7565-4c5c-b2ec-b695b61f9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How is a pair confusion matrix different from a regular confusion matrix, and why might it be useful in certain situations?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a3e318-6389-479e-960b-d397d3a92d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A pair confusion matrix is a specialized form of a confusion matrix that focuses on evaluating the performance of binary classification models on imbalanced datasets. It provides a more detailed analysis of the model's performance by considering the correct and incorrect predictions for each pair of classes individually. Pair confusion matrices can be particularly useful when the dataset has a large class imbalance, as they allow for a more nuanced evaluation of the model's performance on each class.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae89a29-1a3d-476b-bce8-a4b6ada1b331",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f4d5a-5542-4f98-ac72-39b65b460c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is an extrinsic measure in the context of natural language processing, and how is it typically used to evaluate the performance of language models?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f74f9-e824-4f10-bf46-b51c3cbab0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In natural language processing, extrinsic measures are evaluation metrics that assess the performance of a language model in the context of a specific downstream task or application. These measures evaluate how well the language model performs on the task it is intended to solve. For example, in machine translation, an extrinsic measure could be the BLEU score, which evaluates the quality of the translated text compared to a reference translation. Extrinsic measures provide a more realistic evaluation of the language model's effectiveness in real-world scenarios.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b0923e-ecab-4749-ba1d-ecb0776f93a6",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb5043-5189-4d70-93cc-9abc56e67a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is an intrinsic measure in the context of machine learning, and how does it differ from an extrinsic measure?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ed9b5-6769-4687-aa54-7791910e93e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Intrinsic measures, on the other hand, are evaluation metrics that assess the performance of a machine learning model based on its internal characteristics or features, rather than its performance on a specific task or application. These measures are typically applied directly to the model itself, independent of any specific application. For example, in unsupervised learning, intrinsic measures such as the silhouette coefficient or the Davies-Bouldin index are used to evaluate clustering algorithms based on the internal structure and quality of the clusters they produce. Intrinsic measures focus on the model's ability to capture patterns or structures in the data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c34afe6-a253-4736-af9b-a446f13d93db",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d13588c-5b12-46b5-91e3-3041a4bfa3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is the purpose of a confusion matrix in machine learning, and how can it be used to identify strengths and weaknesses of a model?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3cf6eb-e5c7-4873-9d22-1aaaec585d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The purpose of a confusion matrix in machine learning is to provide a detailed breakdown of the predictions made by a classification model. It summarizes the performance of the model by showing the true positive, true negative, false positive, and false negative counts for each class label. From the confusion matrix, various evaluation metrics can be derived, such as accuracy, precision, recall, and F1-score, which help assess the model's performance on different aspects, such as overall correctness, positive predictive power, and sensitivity to true positives. The confusion matrix allows for a deeper understanding of the strengths and weaknesses of the model, highlighting specific areas where it may struggle or excel.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2bebc7-9fdb-4625-bf7a-bc1fadc4ba4e",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b3448-df69-4afe-9f65-7f0659bddd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are some common intrinsic measures used to evaluate the performance of unsupervised learning algorithms, and how can they be interpreted?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27fa1d6-0eaf-4f60-8c87-7a4777a6a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Common intrinsic measures used to evaluate the performance of unsupervised learning algorithms include:\n",
    "\n",
    "Silhouette coefficient: Measures the compactness and separation of clusters, providing an overall assessment of the clustering quality. It ranges from -1 to 1, with higher values indicating better-defined clusters.\n",
    "Davies-Bouldin index: Evaluates the separation and compactness of clusters by considering the distances between clusters and the scatter within clusters. Lower values indicate better clustering quality.\n",
    "Calinski-Harabasz index: Assesses the ratio of between-cluster dispersion to within-cluster dispersion, with higher values indicating better-defined clusters.\n",
    "\n",
    "These intrinsic measures provide insights into the structure and quality of the clusters produced by unsupervised learning algorithms. They help in comparing different algorithms or parameter settings and can guide the selection of the most appropriate clustering solution.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9466a7-8fbc-4073-883d-59e4180b0d55",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ccf63-8ad7-45b1-811e-bfef540f6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are some limitations of using accuracy as a sole evaluation metric for classification tasks, and how can these limitations be addressed?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742f8fe-46f0-407a-a385-cf532c13dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Limitations of using accuracy as a sole evaluation metric for classification tasks include:\n",
    "\n",
    "Class imbalance: Accuracy can be misleading when the dataset has imbalanced class distributions. A high accuracy may be achieved by simply predicting the majority class, while performing poorly on minority classes.\n",
    "Cost-sensitive problems: Different types of errors may have different costs. Accuracy does not consider the relative costs associated with false positives and false negatives.\n",
    "Misinterpretation in skewed datasets: Accuracy alone does not provide information about the actual performance of the model on different classes. It may mask poor performance on important classes.\n",
    "\n",
    "To address these limitations, additional evaluation metrics can be used, such as precision, recall, F1-score, and area under the receiver operating characteristic curve (AUC-ROC). These metrics provide a more comprehensive understanding of the model's performance by considering different aspects, such as the trade-off between true positives and false positives, the ability to detect true positives, and the overall discriminative power of the model.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
