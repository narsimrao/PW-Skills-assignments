{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8eb10ba-e80a-4d11-8fd2-e10894e0c436",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f8a82-f5be-4c07-9d5d-1ea7caba1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is anomaly detection and what is its purpose?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a11aa52-9798-4256-94ee-47aea018906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Anomaly detection, also known as outlier detection, refers to the task of identifying rare, unusual, or anomalous data points or patterns that deviate significantly from the norm or expected behavior within a dataset. The purpose of anomaly detection is to detect and flag observations or instances that are considered abnormal or suspicious, which can be indicative of potential fraud, errors, anomalies, or unusual events.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99766831-55a0-47a5-8b0b-77886f6cbaa6",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f693329a-2f03-4018-bb0f-3f8a8fa3a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are the key challenges in anomaly detection?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47a1b9-2058-48a4-8c52-d8f3651a0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Key challenges in anomaly detection include:\n",
    "\n",
    "Lack of labeled data: Anomalies are often rare, making it difficult to collect a sufficient number of labeled anomalies for training a supervised model.\n",
    "Imbalanced data: Anomalies are typically a minority class, leading to imbalanced datasets and potential bias towards the majority class.\n",
    "Concept drift: The concept of what constitutes an anomaly may change over time, requiring models to adapt and evolve accordingly.\n",
    "High-dimensional data: Anomaly detection becomes more challenging as the dimensionality of the data increases, leading to the curse of dimensionality.\n",
    "Unlabeled anomalies: Anomalies may take various forms, and their characteristics may not be fully known, making it challenging to define and detect them accurately.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b40e7-14ae-41a0-b84a-b21321490e59",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b434cfa-df85-4397-85b6-5eb6f8653310",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cabcfdd-cde2-4cb1-9896-9de6cc0264b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Unsupervised anomaly detection does not rely on labeled anomalies during training. It aims to identify outliers or anomalies in an unlabeled dataset by learning the underlying patterns and structures in the data. On the other hand, supervised anomaly detection requires a labeled dataset where anomalies are explicitly labeled during training. The model learns to differentiate between normal and anomalous instances based on the labeled examples. Unsupervised methods are more suitable when labeled anomaly data is scarce or unavailable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425b2de6-07d3-46e6-b06f-43973efedcb9",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f7661-cf19-4c67-919d-453c1913e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are the main categories of anomaly detection algorithms?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b67f2d2-1be3-4c50-b7c1-4efcbacf9d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The main categories of anomaly detection algorithms are:\n",
    "\n",
    "Statistical methods: These algorithms assume that the normal data follows a known statistical distribution, such as Gaussian distribution, and identify instances that significantly deviate from the expected distribution.\n",
    "Distance-based methods: These algorithms compute distances or dissimilarities between data points and identify instances that are farthest from their neighbors or have unusual neighborhoods.\n",
    "Density-based methods: These algorithms estimate the density of data points and classify instances with low density as anomalies.\n",
    "Clustering-based methods: These algorithms detect anomalies as data points that do not belong to any cluster or are in sparsely populated clusters.\n",
    "Machine learning methods: These algorithms use machine learning techniques to learn patterns from the data and classify instances as normal or anomalous based on the learned models.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2728f348-d9b2-4eab-a3bf-c3546ad4894c",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe44da-40d7-41c3-b9f4-9e4ee5943b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are the main assumptions made by distance-based anomaly detection methods?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba86a6b2-6ebb-421b-94b6-3e819a82826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Distance-based anomaly detection methods make certain assumptions, including:\n",
    "\n",
    "Normal instances are similar to their neighbors, while anomalies are dissimilar or distant from their neighbors.\n",
    "The majority of instances in the dataset are expected to be normal, with only a small percentage of anomalies.\n",
    "Anomalies are likely to have fewer nearby neighbors or fall outside the expected range of distances between neighbors.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52da4fa5-cdf6-462c-8bb5-8723324679bc",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29866403-cfc9-482e-a04a-d09e95831e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How does the LOF algorithm compute anomaly scores?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad90690-c365-458f-b8f3-d84493a23bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Local Outlier Factor (LOF) algorithm computes anomaly scores based on the local density deviation of a data point compared to its neighbors. The algorithm calculates a density-based reachability distance for each point, representing how well-connected it is to its neighbors. An anomaly score is obtained by comparing the local reachability density of a point with that of its neighbors. Points with significantly lower local reachability density compared to their neighbors are considered anomalies.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e3cef3-2a6b-4d41-b651-21b149b59566",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d691f4-7b4a-401f-83dd-8625271da121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are the key parameters of the Isolation Forest algorithm?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da583ae-1d5d-42fb-83d1-db3dd01012ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The key parameters of the Isolation Forest algorithm are:\n",
    "\n",
    "n_estimators: The number of isolation trees to be created. Increasing the number of trees improves the performance but also increases computation time.\n",
    "max_samples: The number of samples to be randomly selected as split candidates when building each tree. Higher values increase randomness and resilience to outliers but also increase memory usage and computation time.\n",
    "contamination: The expected proportion of anomalies in the dataset. It helps in determining the threshold for classifying instances as anomalies.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c2c72-c9e4-4660-800c-ed761eebe49e",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a744ed50-bd4d-41ca-a114-92ab6fdc73c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dd0730-a6a7-4069-b0e0-cfecd6c5ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In K-nearest neighbors (KNN) with K=10, if a data point has only 2 neighbors of the same class within a radius of 0.5, its anomaly score would be relatively high. Since it has very few neighbors within the given radius, it indicates that the data point is located in a sparsely populated region and deviates from the expected distribution of the majority class. The exact anomaly score would depend on the algorithm used and the specific calculation method for anomaly scores.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188d129-0bf4-4043-b28f-b1ec2465d9d5",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcfda0e-432c-4d1f-916d-2446b0120173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f9af20-7285-469c-8606-0c30a311dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In the Isolation Forest algorithm, the anomaly score for a data point is determined by its average path length compared to the average path length of the trees in the forest. A shorter average path length indicates that the data point is easier to isolate and, therefore, more likely to be an anomaly. However, without knowing the specific average path lengths of the other data points in the dataset, it is not possible to determine the exact anomaly score for a data point based solely on its average path length of 5.0.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
