{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ca820e-cc9b-43ab-b74c-ba8bdb0e034c",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc6c72d-9fc9-4462-87f1-a579bd881315",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is hierarchical clustering, and how is it different from other clustering techniques?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a2265-4ec5-4120-94d9-790951dd62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hierarchical clustering is a clustering technique that creates a hierarchy of clusters by successively merging or splitting them. It is different from other clustering techniques in that it does not require specifying the number of clusters in advance and produces a tree-like structure called a dendrogram, representing the clustering hierarchy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9385a9e-a500-4817-8d37-a43c751a6cff",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8fe123-8c4a-4cdc-98a2-eb3151a404e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are the two main types of hierarchical clustering algorithms? Describe each in brief.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f9bae-2c53-4cae-b3b8-2730a0d38ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Agglomerative Hierarchical Clustering: Starts with each data point as an individual cluster and then iteratively merges the closest clusters until a single cluster remains.\n",
    "Divisive Hierarchical Clustering: Begins with a single cluster containing all data points and recursively splits clusters into smaller ones until each data point is in its own cluster.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e7f605-74d7-4974-81b0-b5bea5af4430",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004764cf-7c2a-42b6-84c5-7719464d4120",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How do you determine the distance between two clusters in hierarchical clustering, and what are the common distance metrics used?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160024be-edbc-499c-bc26-fb233f2535d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The distance between two clusters in hierarchical clustering is determined using various distance metrics. Commonly used distance metrics include:\n",
    "\n",
    "Euclidean Distance: Computes the straight-line distance between two points in Euclidean space.\n",
    "Manhattan Distance: Calculates the sum of absolute differences between the coordinates of two points.\n",
    "Cosine Similarity: Measures the cosine of the angle between two vectors, indicating their similarity regardless of magnitude.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1ae683-0564-41aa-b275-c0222203619e",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc6aaa-7709-46c4-a351-bbed3ba39c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How do you determine the optimal number of clusters in hierarchical clustering, and what are some common methods used for this purpose?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab480ad-0498-4876-be5a-2b3c885e0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dendrogram Analysis: Examining the dendrogram to identify a suitable cutoff point, where the vertical distance between merges is significant.\n",
    "Gap Statistic: Comparing the within-cluster sum of squares with null reference distributions to find the optimal number of clusters.\n",
    "Silhouette Coefficient: Calculating the average silhouette coefficient for different numbers of clusters and selecting the highest value.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c029fb4-8eae-4bb0-836b-163d71c6bd8f",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b9e08e-6da5-477c-8730-41f8b228e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are dendrograms in hierarchical clustering, and how are they useful in analyzing the results?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6db1ba-51bf-4fef-96b5-5b81afb34437",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Illustrate the merging or splitting of clusters at different levels.\n",
    "Show the distances between clusters.\n",
    "Aid in determining the optimal number of clusters by visually inspecting the dendrogram structure.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388eff9f-ba51-4890-a3ff-25f48d1676b7",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67269ef-0472-46b3-8e9a-2d1fd5ce4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Can hierarchical clustering be used for both numerical and categorical data? If yes, how are the distance metrics different for each type of data?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea4e7b-88a4-4a74-8dec-d70b07c26a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hierarchical clustering can be used for both numerical and categorical data. The distance metrics differ for each type of data:\n",
    "\n",
    "Numerical Data: Common distance metrics like Euclidean distance and Manhattan distance can be used.\n",
    "Categorical Data: Different metrics like the Jaccard coefficient or Hamming distance are used to calculate the dissimilarity between categorical variables.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b202508-b81c-47a3-926b-388af75aeb30",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6312669f-db23-4dfe-a7b1-2c50dd5f75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How can you use hierarchical clustering to identify outliers or anomalies in your data?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e4c5c-6925-43ed-a4d0-c8d95c88d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hierarchical clustering can be used to identify outliers or anomalies in data by:\n",
    "\n",
    "Examining the height of the dendrogram branches: Outliers are often represented by long branches or isolated clusters with very few data points.\n",
    "Observing cluster assignments: Data points assigned to very small or singleton clusters can be considered potential outliers.\n",
    "Analyzing dissimilarity measures: Outliers can have high dissimilarity values with other data points or clusters, indicating their distinctiveness.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
