{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eb1374d-3c59-4e29-b3cc-28834ebc7058",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee107dc-ebce-4db4-a479-fe1c79857ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is the purpose of grid search cv in machine learning, and how does it work?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e344909-ffe7-42a0-b4d3-5d03f628bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The purpose of grid search cv (cross-validation) in machine learning is to systematically search for the best combination of hyperparameters for a given model. It works by defining a grid of hyperparameter values to explore, and then evaluating the model's performance using cross-validation on each combination of hyperparameters. The combination that yields the best performance metric is selected as the optimal set of hyperparameters.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc101985-8ea7-4b9b-9f87-e2a486e1279b",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885c7e9-5426-4165-ad48-4aad2baa5c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Describe the difference between grid search cv and randomize search cv, and when might you choose one over the other?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1179c0b-7280-4958-a533-8ebf8ff4f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Grid search cv and randomize search cv are both techniques for hyperparameter tuning, but they differ in how they explore the hyperparameter space. Grid search cv exhaustively searches through all possible combinations of hyperparameter values specified in a grid, whereas randomize search cv randomly samples from the defined hyperparameter space. Grid search cv is suitable when the hyperparameter space is relatively small and computationally feasible to explore, while randomize search cv is preferred when the hyperparameter space is large and exploring all combinations is not practical or time-efficient.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285cb4af-7982-43e4-89c1-3bec2ed04671",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab40af-e252-49c7-8637-a10ad68f1f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is data leakage, and why is it a problem in machine learning? Provide an example.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d5cc8b-7608-4861-ab4f-fcc71be45324",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data leakage refers to the situation where information from outside the training data is used in the model training process, leading to overly optimistic performance estimates. It is a problem in machine learning because it can result in models that perform well during training and validation but fail to generalize to unseen data in real-world scenarios. An example of data leakage is including information from the target variable in the features used for training the model. For instance, using future knowledge that would not be available at the time of prediction can lead to artificially high performance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3248752-ff12-4e34-85bb-a7f974630790",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d741e9-4cd8-4350-8cf1-950889818919",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How can you prevent data leakage when building a machine learning model?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06b1b6-99c5-49cc-990c-88799a8fa1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To prevent data leakage when building a machine learning model, it is important to ensure that the model training process does not have access to information that would not be available in real-world scenarios. Some strategies to prevent data leakage include:\n",
    "\n",
    "Splitting the data into separate training and testing sets before any preprocessing or feature engineering steps.\n",
    "Avoiding the use of future information or target variables in the feature engineering process.\n",
    "Applying feature scaling, transformations, or imputations separately for each fold during cross-validation to prevent information leakage between folds.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b12b44-cbc8-4720-a192-32a1baff4b6b",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33090765-57af-461c-a502-a585033f1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is a confusion matrix, and what does it tell you about the performance of a classification model?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc62056-48b1-42d3-8a29-b8fa0a2716ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A confusion matrix is a table that summarizes the performance of a classification model by presenting the counts of true positive (TP), true negative (TN), false positive (FP), and false negative (FN) predictions. It provides a comprehensive view of the model's predictions and allows for the calculation of various performance metrics.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebf1ad5-207d-4632-b673-d82f7005699c",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4858a-a36b-4e73-a571-da8948cd2d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Explain the difference between precision and recall in the context of a confusion matrix.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad7f68-6298-4d9c-8551-91805d2c1009",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Precision and recall are performance metrics derived from a confusion matrix, and they represent different aspects of the model's performance:\n",
    "\n",
    "Precision is the ratio of true positives (TP) to the sum of true positives and false positives (FP). It measures the proportion of correctly predicted positive instances among all instances predicted as positive. Precision focuses on the accuracy of positive predictions.\n",
    "Recall, also known as sensitivity or true positive rate, is the ratio of true positives (TP) to the sum of true positives and false negatives (FN). It measures the proportion of correctly predicted positive instances among all actual positive instances. Recall focuses on capturing all positive instances correctly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd93de-168a-4455-af43-10e90f9717d7",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd44cdb-ade5-44ff-b29f-1f20ed6980cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How can you interpret a confusion matrix to determine which types of errors your model is making?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76770e50-1b0a-4bbd-9098-cc5ee548f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "By examining the values in a confusion matrix, you can identify different types of errors made by the model:\n",
    "\n",
    "False positives (FP): Instances wrongly classified as positive.\n",
    "False negatives (FN): Instances wrongly classified as negative.\n",
    "True positives (TP): Instances correctly classified as positive.\n",
    "True negatives (TN): Instances correctly classified as negative.\n",
    "\n",
    "Analyzing these values helps determine the nature and frequency of errors made by the model, providing insights into areas for improvement.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82592750-e617-40e0-bcd3-14690c0764ac",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27209cf-1151-43ec-9159-502eecd55392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are some common metrics that can be derived from a confusion matrix, and how are they calculated?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff07a5d-fc86-4dea-a45d-b4ea6c6ff3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Common metrics derived from a confusion matrix include:\n",
    "\n",
    "Accuracy: The overall proportion of correct predictions, calculated as (TP + TN) / (TP + TN + FP + FN).\n",
    "Precision: The proportion of correctly predicted positive instances among all instances predicted as positive, calculated as TP / (TP + FP).\n",
    "Recall (Sensitivity): The proportion of correctly predicted positive instances among all actual positive instances, calculated as TP / (TP + FN).\n",
    "F1 score: The harmonic mean of precision and recall, providing a balanced measure between the two metrics, calculated as 2 * (precision * recall) / (precision + recall).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d4da34-a521-4a45-9f16-c1a63e09c395",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f6b1d5-2f07-40e5-b14c-dba127d3c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is the relationship between the accuracy of a model and the values in its confusion matrix?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b174caeb-1bc6-4025-bc3d-21835769d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The accuracy of a model is reflected in the values of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) in the confusion matrix. Accuracy is calculated as (TP + TN) / (TP + TN + FP + FN). It represents the overall correctness of the model's predictions, regardless of the specific types of errors.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d80ac-37e3-4d8c-a961-27dc61d84248",
   "metadata": {},
   "source": [
    "# Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0892f5e9-dc71-4793-84a3-274ac51a4922",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How can you use a confusion matrix to identify potential biases or limitations in your machine learning model?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92bd54a-7a76-45aa-883c-bc7d4b692d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A confusion matrix can help identify potential biases or limitations in a machine learning model by examining the distribution of errors across different classes. For example:\n",
    "\n",
    "If the model consistently misclassifies one class as another, it may indicate a bias or difficulty in distinguishing between those classes.\n",
    "If the model has a significantly higher number of false positives or false negatives for a specific class, it could point to issues such as class imbalance or a higher misclassification cost for that class.\n",
    "By analyzing the patterns in the confusion matrix, adjustments can be made to address specific biases or limitations, such as collecting more data for underrepresented classes or adjusting the model's decision threshold.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
